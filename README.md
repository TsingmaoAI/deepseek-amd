
# ä¸€é”®éƒ¨ç½²æ•™ç¨‹ ğŸš€ï¼ˆæ¨èæ–¹å¼ï¼‰

> **æ¨èç”¨æˆ·ä¼˜å…ˆä½¿ç”¨æ­¤æ–¹å¼å®Œæˆéƒ¨ç½²ï¼Œæ“ä½œç®€å•ã€æ— éœ€å‘½ä»¤è¡ŒåŸºç¡€ã€‚**

1. è§£å‹ **aipc-ds.zip** å‹ç¼©åŒ…ï¼Œè¿è¡Œå…¶ä¸­çš„ `setup` å®‰è£…è½¯ä»¶ä¸»ä½“ï¼›  
2. å¯è‡ªè¡Œé€‰æ‹©å®‰è£…ä½ç½®ï¼›  
3. åœ¨è¿è¡Œå‰**åŠ¡å¿…å°†æ¨¡å‹æƒé‡æ‰€æœ‰æ–‡ä»¶å¤¹**æ”¾å…¥å®‰è£…ç›®å½•ä¸‹çš„ `AIPC-DS\ds-amd\_internal\models` æ–‡ä»¶å¤¹ä¸­ï¼›  
4. åŒå‡»è¿è¡Œæ¡Œé¢å›¾æ ‡æˆ– `AIPC.exe` å¯åŠ¨ç¨‹åºã€‚

ğŸ“¦ å®‰è£…åŒ…ä¸‹è½½é“¾æ¥ï¼ˆé€šè¿‡ç™¾åº¦ç½‘ç›˜åˆ†äº«ï¼‰ï¼š  
**[ ç‚¹å‡»ä¸‹è½½ aipc-ds.zip ](https://pan.baidu.com/s/1CjGXViEEK2A0SjgXUruLLA?pwd=ecxk)** æå–ç : `ecxk`

# Introduction
åœ¨AMD Ryzenç³»åˆ—èŠ¯ç‰‡ä¸Šéƒ¨ç½²deepseekæ¨¡å‹ï¼Œæ”¯æŒçš„æ¨¡å‹åˆ—è¡¨å¦‚ä¸‹ï¼š

- [DeepSeek-R1-Distill-Qwen-1.5B](https://huggingface.co/amd/DeepSeek-R1-Distill-Qwen-1.5B-awq-asym-uint4-g128-lmhead-onnx-hybrid)
- [DeepSeek-R1-Distill-Llama-8B](https://huggingface.co/amd/DeepSeek-R1-Distill-Llama-8B-awq-asym-uint4-g128-lmhead-onnx-hybrid)
- [DeepSeek-R1-Distill-Qwen-7B](https://huggingface.co/amd/DeepSeek-R1-Distill-Qwen-7B-awq-asym-uint4-g128-lmhead-onnx-hybrid)

# Supported computer configuration
ä»…æ”¯æŒè¿è¡ŒWindows 11çš„Strix ï¼ˆSTXï¼‰å’ŒKrackan Point ï¼ˆKRKï¼‰å¤„ç†å™¨ã€‚



# Requirements
- NPUé©±åŠ¨ï¼Œå¯å‚è€ƒ[NPU](https://ryzenai.docs.amd.com/en/latest/inst.html)

- iGPUé©±åŠ¨ï¼Œå¯å‚è€ƒ[iGPU](https://www.amd.com/en/support/download/drivers.html)

- ä¸‹è½½å¿…è¦çš„.wheelæ–‡ä»¶ä¸.dllæ–‡ä»¶ï¼Œä¸‹è½½é“¾æ¥ï¼š[wheel](),ä¸‹è½½å¹¶è§£å‹å®Œæˆåå°†å…¶ä¸­çš„wheelå’Œdllæ–‡ä»¶æ‹·è´åˆ°`wheel`ç›®å½•ä¸‹

# Execution using Python

## ç¯å¢ƒå‡†å¤‡
1. åˆ›å»ºcondaç¯å¢ƒ
```bash
conda create --name <env name> python=3.10
```
2. æ¿€æ´»condaç¯å¢ƒ
```bash
conda activate <env name>
```
3. å®‰è£…wheelæ–‡ä»¶
```bash
cd wheel
pip install onnxruntime_genai-0.4.0.dev0-cp310-cp310-win_amd64.whl
pip install onnxruntime_directml-1.20.1-cp310-cp310-win_amd64.whl
```
4. å®‰è£…requirements
```bash
pip install -i requirements.txt
```
## æ¨¡å‹å‡†å¤‡
1. ä»[huggingface]( https://huggingface.co/collections/amd/amd-ryzenai-deepseek-r1-distill-hybrid-67a53471e9d5f14bece775d2)ä¸‹è½½æ‰€éœ€çš„æ¨¡å‹ï¼Œå¹¶å°†æ¨¡å‹æ‹·è´åˆ°`models`ç›®å½•ä¸‹

2. æ‰“å¼€`genai_config.json`æ–‡ä»¶ã€‚ä½äºå·²ä¸‹è½½æ¨¡å‹æ–‡ä»¶å¤¹ä¸­çš„æ–‡ä»¶ã€‚ä½¿ç”¨ä½äº`wheel`æ–‡ä»¶å¤¹ä¸­çš„`onnx_custom_ops.dll`çš„å®Œæ•´è·¯å¾„æ›´æ–°`custom_ops_library`çš„å€¼.
```bash
"session_options": {
          ...
          "custom_ops_library":"wheel\\onnx_custom_ops.dll",
          ...
}
```

## è¿è¡Œæ¨¡å‹

### æ–¹å¼1(éæ¥å£è®¿é—®)
```bash
python run_model.py --model_dir path_to\your\model
```

### æ–¹å¼2(æ¥å£è®¿é—®)

#### ç®€å•å¼€å§‹
ä¿®æ”¹server.pyä¸­çš„models_pathså€¼ä¸ºä½ çš„æ¨¡å‹è·¯å¾„ã€‚
```bash
models_paths = {"DeepSeek-R1-Distill-Qwen-1.5B":"path\\to\\DeepSeek-R1-Distill-Qwen-1.5B-awq-asym-uint4-g128-lmhead-onnx-hybrid ",
                "DeepSeek-R1-Distill-Llama-8B":"path\\to\\DeepSeek-R1-Distill-Llama-8B-awq-asym-uint4-g128-lmhead-onnx-hybrid",
                "DeepSeek-R1-Distill-Qwen-7B":"path\\to\\DeepSeek-R1-Distill-Qwen-7B-awq-asym-uint4-g128-lmhead-onnx-hybrid"
              }
```
å¼€å¯æ¥å£æœåŠ¡
```bash
python server.py --port 9090
```

#### API Endpoints

##### Get `/health` : Returns heath check result

- Body : `{"status": "ok" }`
- the model is successfully loaded and the server is ready.

##### Post `/v1/chat/completions`: Given a `prompt`,it returns the result of reasoning

example :
```bash
{"input":"Please solve following problem and explain it to me. Then give me final answer at the end with a single number preceded by string '#### '. Question: Rory orders 2 subs for $7.50 each, 2 bags of chips for $1.50 each and 2 cookies for $1.00 each for delivery.\nAnswer:"}
```

##### Post `/change_model`: change the servering model

example:
```bash
{
    "model_name":"DeepSeek-R1-Distill-Qwen-7B"
}
```











